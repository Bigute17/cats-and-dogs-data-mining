{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new folders for respective classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('dogs-vs-cats/images/cat')\n",
    "os.mkdir('dogs-vs-cats/images/dog')\n",
    "\n",
    "folder = 'dogs-vs-cats/images/'\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith('cat.'):\n",
    "        shutil.move(folder + file, folder + 'cat')\n",
    "    elif file.startswith('dog.'):\n",
    "        shutil.move(folder + file, folder + 'dog')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = Path('../cats-and-dogs-data-mining/dogs-vs-cats/images/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create filepath dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = list(image_dir.glob(r'**/*.jpg')) #find all .jpg files within the current folder\n",
    "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths)) #how we pull labels\n",
    "\n",
    "filepaths = pd.Series(filepaths, name = 'Filepath').astype(str)\n",
    "labels = pd.Series(labels, name = 'Label')\n",
    "\n",
    "image_df = pd.concat([filepaths, labels], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(image_df, train_size = 0.7, shuffle = True, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows us to load a subset of images at a time, train them and recycle the memory so we don't run out\n",
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255, # scale pixel intensity values from 0 - 255 down to 0 - 1\n",
    "    horizontal_flip=True, # Make our model more resilient to horizontally flipped pics\n",
    "    width_shift_range=0.2, # Shift width by 20%\n",
    "    height_shift_range=0.2, # Shift height by 20%\n",
    "    validation_split = 0.2 # Pull train and test images through the same generato\n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow the images (specify how the images will be loaded)\n",
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    x_col=\"Filepath\",\n",
    "    y_col=\"Label\",\n",
    "    target_size = (224,224), # Standardize image size\n",
    "    color_mode='rgb', # Our images are colorized\n",
    "    class_mode='binary', # we have 2 classes only\n",
    "    batch_size = 32, # how many images to load at a time\n",
    "    shuffle = True, # Shuffle for training\n",
    "    seed=42, # makes sure the shuffling is always the same way, and always the same subset\n",
    "    subset = 'training'\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    x_col=\"Filepath\",\n",
    "    y_col=\"Label\",\n",
    "    target_size = (224,224), # Standardize image size\n",
    "    color_mode='rgb', # Our images are colorized\n",
    "    class_mode='binary', # we have 2 classes only\n",
    "    batch_size = 32, # how many images to load at a time\n",
    "    shuffle = True, # Shuffle for training\n",
    "    seed=42, # makes sure the shuffling is always the same way, and always the same subset\n",
    "    subset = 'validation'\n",
    ")\n",
    "\n",
    "test_images = train_generator.flow_from_dataframe(\n",
    "    dataframe = test_df,\n",
    "    x_col=\"Filepath\",\n",
    "    y_col=\"Label\",\n",
    "    target_size = (224,224), # Standardize image size\n",
    "    color_mode='rgb', # Our images are colorized\n",
    "    class_mode='binary', # we have 2 classes only\n",
    "    batch_size = 32, # how many images to load at a time\n",
    "    shuffle = False, # False since we are only evaluating, not training\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.6703 - accuracy: 0.5737"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     optimizer \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     metrics \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# 100 epochs with early stopping callback. Early stopping will look at the validation loss so we can\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# monitor the validation loss, when the val loss has not improved after 5 epochs, it will stop\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# training and restore the weights from the best epoch\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# We chose to reduce the learning rate to stabilize model training. Validation loss was fluctuating\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# a lot previously.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     train_images,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     validation_data \u001b[39m=\u001b[39;49m val_images,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     epochs \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     callbacks \u001b[39m=\u001b[39;49m [\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mEarlyStopping(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m             monitor \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mval_loss\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m             patience \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m             restore_best_weights \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m         ),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mReduceLROnPlateau(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m             monitor \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mval_loss\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m             patience \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m         )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X22sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py:1694\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[1;32m   1681\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[1;32m   1682\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1692\u001b[0m         steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution,\n\u001b[1;32m   1693\u001b[0m     )\n\u001b[0;32m-> 1694\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m   1695\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m   1696\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m   1697\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[1;32m   1698\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[1;32m   1699\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   1700\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1701\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1702\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1703\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1704\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1705\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1706\u001b[0m )\n\u001b[1;32m   1707\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1708\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1709\u001b[0m }\n\u001b[1;32m   1710\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py:2040\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2036\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   2037\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   2038\u001b[0m ):\n\u001b[1;32m   2039\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2040\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[1;32m   2041\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   2042\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    917\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 919\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    920\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    921\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    922\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(224, 224, 3)) # One for each color channel\n",
    "# 16 filters, kernal size of 3x3. \n",
    "# The convolutional layer will look at the image, slide a window across the image, and the window\n",
    "# weights will multiply by the pixel values, sum them up, and send that to a new 2D feature\n",
    "# We will end up with a new 2D array with the values. \n",
    "# Filters specify how many times we want to do this full pass over the image.\n",
    "# The kernal size represents how big the window is\n",
    "# The whole point of a Convolutional Neural Network is to extract features that \n",
    "# are useful for predicting\n",
    "# If we were to pass each pixel as an individual feature, the model would be too complex and likely\n",
    "# overfit. Also, there is no way to capture the spatial relationship between the data\n",
    "x = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "# maxpool also sends a window across the image, and takes a max of 4 pixels.\n",
    "# allows the next convolutional data to reduce the dimensions of the data and keep the most\n",
    "# important pixels (simplified, high level view of each image)\n",
    "# Each time we maxpool, we lose information, but make it easier for the next layer to grasp\n",
    "# high level relationships in the data\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation = 'relu')(x)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "# Average over the first 2 dimensions so that we just end up with 32 features. \n",
    "# These features could be anything like pointy ears for cats, or floppy ears for dogs\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "# create the actual classifier, a 2 hidden layer dense NN\n",
    "x = tf.keras.layers.Dense(128, activation = 'relu')(x)\n",
    "x = tf.keras.layers.Dense(128, activation = 'relu')(x)\n",
    "# outputs is another dense layer with 1 output value and sigmoid activation since\n",
    "# it is a binary classification task\n",
    "# sigmoid gives it the effect of being betweem 0 or 1\n",
    "# so the output is a single prob estimate of the prob that one of the classes is present in the image\n",
    "# In this case, 1 = dog and 0 = cat\n",
    "# So the output is the probability of a dog since that is the positive class\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "# Model compiler with adam optimizer, binary crossentropy loss, and accuracy as the metric\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "# 100 epochs with early stopping callback. Early stopping will look at the validation loss so we can\n",
    "# monitor the validation loss, when the val loss has not improved after 5 epochs, it will stop\n",
    "# training and restore the weights from the best epoch\n",
    "# We chose to reduce the learning rate to stabilize model training. Validation loss was fluctuating\n",
    "# a lot previously.\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data = val_images,\n",
    "    epochs = 100,\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor = \"val_loss\",\n",
    "            patience = 5,\n",
    "            restore_best_weights = True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor = \"val_loss\",\n",
    "            patience = 3\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'Functional' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/blakecurtsinger/Documents/cats-and-dogs-data-mining/work.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49msummary(model)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py:3297\u001b[0m, in \u001b[0;36mModel.summary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[1;32m   3291\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt:\n\u001b[1;32m   3292\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   3293\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis model has not yet been built. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3294\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3295\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe model on a batch of data.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3296\u001b[0m     )\n\u001b[0;32m-> 3297\u001b[0m layer_utils\u001b[39m.\u001b[39;49mprint_summary(\n\u001b[1;32m   3298\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   3299\u001b[0m     line_length\u001b[39m=\u001b[39;49mline_length,\n\u001b[1;32m   3300\u001b[0m     positions\u001b[39m=\u001b[39;49mpositions,\n\u001b[1;32m   3301\u001b[0m     print_fn\u001b[39m=\u001b[39;49mprint_fn,\n\u001b[1;32m   3302\u001b[0m     expand_nested\u001b[39m=\u001b[39;49mexpand_nested,\n\u001b[1;32m   3303\u001b[0m     show_trainable\u001b[39m=\u001b[39;49mshow_trainable,\n\u001b[1;32m   3304\u001b[0m     layer_range\u001b[39m=\u001b[39;49mlayer_range,\n\u001b[1;32m   3305\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/layer_utils.py:257\u001b[0m, in \u001b[0;36mprint_summary\u001b[0;34m(model, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[1;32m    255\u001b[0m positions \u001b[39m=\u001b[39m positions \u001b[39mor\u001b[39;00m [\u001b[39m0.45\u001b[39m, \u001b[39m0.85\u001b[39m, \u001b[39m1.0\u001b[39m]\n\u001b[1;32m    256\u001b[0m \u001b[39mif\u001b[39;00m positions[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 257\u001b[0m     positions \u001b[39m=\u001b[39m [\u001b[39mint\u001b[39m(line_length \u001b[39m*\u001b[39m p) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m positions]\n\u001b[1;32m    258\u001b[0m \u001b[39m# header names for the different log elements\u001b[39;00m\n\u001b[1;32m    259\u001b[0m to_display \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mLayer (type)\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mOutput Shape\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mParam #\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/layer_utils.py:257\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    255\u001b[0m positions \u001b[39m=\u001b[39m positions \u001b[39mor\u001b[39;00m [\u001b[39m0.45\u001b[39m, \u001b[39m0.85\u001b[39m, \u001b[39m1.0\u001b[39m]\n\u001b[1;32m    256\u001b[0m \u001b[39mif\u001b[39;00m positions[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 257\u001b[0m     positions \u001b[39m=\u001b[39m [\u001b[39mint\u001b[39m(line_length \u001b[39m*\u001b[39;49m p) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m positions]\n\u001b[1;32m    258\u001b[0m \u001b[39m# header names for the different log elements\u001b[39;00m\n\u001b[1;32m    259\u001b[0m to_display \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mLayer (type)\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mOutput Shape\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mParam #\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'Functional' and 'float'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
